#+TITLE: HPI: Fission talk

# meta-structure:

# 1. intro (??)
# 2. motivation/story
# 3. prior art and how HPI is different (focus on interop rather than UI)
# 4. architecture?
# 5. what's next?


* STRT 1. HPI
# EST: 1 min
Human Programming Interface, programmatic offline API to your personal data.

# probably easier to show than to describe what it is
** TODO [#A] quick demo
# (somewhat confusingly, the package name is =my=, so everywhere you see =import my=, it means "HPI")
# the basic idea is that I can just import the data as python objects (although it doesn't have to be python)

maybe discord?
shorten the messages maybe?
: hpi query my.discord.messages -o pprint | grep HPI | head -n 3                                                                                                                                                                                 22:06:01
:  Message(message_id=800446427100348456, timestamp=datetime.datetime(2021, 1, 17, 19, 28, 19, 796000, tzinfo=datetime.timezone.utc), channel=Channel(channel_id=800189382837534720, name='promnesia', server=Server(server_id=727903265437777944, name='The Productivists')), content='https://github.com/karlicoss/HPI/blob/master/doc/SETUP.org#data-flow this might also clarify some things', attachments=''),
:  Message(message_id=800446094458617856, timestamp=datetime.datetime(2021, 1, 17, 19, 27, 0, 488000, tzinfo=datetime.timezone.utc), channel=Channel(channel_id=800189382837534720, name='promnesia', server=Server(server_id=727903265437777944, name='The Productivists')), content="I've gotta go now, but read up on HPI in the meantime! Or if you're interested in reddit data in particular you can start with setting up https://github.com/karlicoss/rexport#setting-up", attachments=''),
:  Message(message_id=800445310596808705, timestamp=datetime.datetime(2021, 1, 17, 19, 23, 53, 601000, tzinfo=datetime.timezone.utc), channel=Channel(channel_id=800189382837534720, name='promnesia', server=Server(server_id=727903265437777944, name='The Productivists')), content="you might need `pip3 install --user promnesia[HPI]` , but I recommend reading up on HPI first just to understand how it's all set up", attachments=''),
composable with familiar tools
*** TODO maybe demonstrate with import first? and then various features?

* TODO [#B] 1. Demonstrations
** TODO for interactive demo maybe do =import my.= and tab? just explore some random data which is mostly public
maybe mess with pandas...
** TODO do a live demo? maybe in jupyterlab? dunno

* STRT 1. Modules
# TODO EST: ???
just a quick overview, not sure if there is much to talk about here

# https://github.com/karlicoss/HPI#whats-inside
# https://github.com/seanbreckenridge/HPI#my-modules
** TODO execute the same thing as in HPI?
# could say 'fun fact -- this list is programmatically generated by HPI'

#+begin_src python :results output table drawer :exports results
from my.core.discovery_pure import all_modules
modules = all_modules()
with_doc = [m for m in modules if m.doc is not None]
for m in with_doc:
    firstline = m.doc.strip().splitlines()[0]
    mlink = f'[[https://github.com/karlicoss/HPI/tree/master/{m.file}][={m.name}=]]'
    print(f'| {mlink} | {firstline} |')
#+end_src


* TODO Story
TODO smth about the singularity

# I've been raised by scifi and was dreaming (still am!) of technological singularity and how computers would aug

As a programmer of I chose to solve these problems by writing more code.
# although with time I'm getting more and more convinced that some of these should be regulated

* Why?
** computers should augment my mental powers
# instead, phones are just toys, and we're at mercy of apple/google duopoly
# it restricts out computing capabilities
# with security as an 'excuse' (it's a spectrum!)

** data is siloed
# big tech has lots of data on you, but it
# Anectodal, but I've never shared worries that 'com'
# I'm yet to see relevant Amazon recommendations
# and all instagram shows to me is cheesy programming humor


* Why
- why can't I have unified map of my favorite places?

* Sad reality
- there are tons of apps & services


* Humble goal: 'data mirror'
# https://beepb00p.xyz/sad-infra.html#data_mirror

- something that runs on the client side and syncs the data locally
- data bindings to interpret the data and use in

Ideally this would be provided by the service instead
Fun fact: phone apps are often basically data mirrors.

- runs on client, syncs data to cache (usually sqlite database)
  # at least on android
- relatively easy to interact with the database
  # ... if not for hostile ecosystem which prevents me from seeing my own data

Mirror because for now, only read only?
Even with that I'd be relatively happy.

* ... how it's going?

my infra map... for a laugh
https://beepb00p.xyz/myinfra.html#mypkg
https://beepb00p.xyz/myinfra_files/myinfra.svg

* TODO maybe start with what integrations I have and what's in progress
and then could talk about more 'boring' bits

* What does it solve?
** local/offline interfaces
Even if you do have internet, search on most sites sucks hard.
Even remembering where exactly you need to search is a cognitive overhead.
- TODO show F2 keybinding?
- orger
*** TODO link to search article?

** quantified self
We have lots of data, yet no insight from it.
# perhaps except the 'insight' big tech gets for ads purposes
Imagine if you could have a system which automatically finds interesting correlations and TODO

** siphons

** dead services
- =my.endomondo=
** migrating/lock-in protection
- =my.rtm=
  I'm not using Remember The Milk anymore, but have a data mirror, so I can search in old tasks.

** memex

* Features
- local-first (actually fully offline!)
** TODO enriching data (e.g. timezone provider)


* Files are great!
- easy to understand and reason about
  # low entry barrier
  # e.g. in comparison do you remember how to make sure your database readers don't crash if anyone is writing into it
  # of course assumes 'immutable', append-only model?
- easy to interoperate (cmdline tools)
- easy to backup
- easy to sync (syncthing/dropbox)

* You don't always need 'apps'
Any app inevitably restricts you, imposing a schema.
# in comparison apps often force fixes set of fields on you, restricting the context etc
- plaintext input, e.g. markdown/org-mode/csv, just in your text editor
  # often you figure out the best schema in process, you can't predict it in advance
  # e.g. exercise tracking, depending on the exercise you do it might be different
- track/input data first, parse later

* Why?
** shared patterns (what is 'hpi' as a library?)
Shared design principles for exporting data
This way it differs from a bunch of separate
Extracting in =my.core=

* TODO Prior art/similar projects
** TODO mention proprietary platforms?
I don't believe they can really work, at least without being partially open sources because of the vastness of data sources.
** Memex by Andrew Louis
Very well built, but not open source :(
** Dogsheep
xx
** Perkeep
Seems to be centered on storage model (objects?).
E.g. I struggled to inspect objects, and it seems to be HTTP api-centric
# it does have some nice interfaces though
# Hope to give it a one more go, HPI can be used as the source of input data.
** TODO ????
* Why 'programmatic'?
Very important!
** TODO maybe swap/interleave with prior art?
** TODO mention about python configs?
https://beepb00p.xyz/configs-suck.html

- just 'import' the configs and you're all set
- configs are flexible
- free linting tools: =mypy= , =pylint=, etc.
- security is not a concern here

* Tyranny of databases
- choosing schema is hard
  # often you don't even know the schema, you have to reverse engineer it
  # if you're only picking certain attributes, you might miss on data if the API changes
  # if you're a hoarder like me it's inacceptable :)
- migrations are hard
- not everything fits into the relational model
  https://beepb00p.xyz/unnecessary-db.html
- sqlite types suck
  # not to spawn a typed vs untyped debate, but you
- databases do not forgive errors
  # bad database migration: you might ruin the data
  # bad 'normalising' -- your program crashes
  #   and even that is possible to work around defensively

** But databases are good!
Of course databases are very useful
- efficient storage
- fast access
- query language

** Best of both worlds?
*** TODO cachew

* We need code!
- composable
- interoperable
- possible to abstract
- much saner error handling
  # even if you don't test the code, worst thing that could happen is crashing
  # acceptable for our purposes
** TODO slide how my approach solves issues with databases

* TLDR
My approach
- during data export, keep raw data intact
  # so concentrate on making the export step robust
  # you can always cleanup the data later
- parse every time from scratch & reconstruct the full TODO?
- if necessary, use cache
# There are exceptions, but I've found that works suprisingly well in most cases
# TODO maybe mention exceptions

* One-way

TODO
It's not strictly necessary, but this seems like a much much harder problem.

* TODO some diagram
link to myinfra


* Design
** TODO synthetic exports?
** 'quasi-continuous'
# possible to make it 'almost' continuous by using streaming APIs or polling some endpoint
# just a bit harder so I didn't invest time in it so far

* TODO merging data?
- github: merges GDPR export (manual, but complete) + API data (automatic, but incomplete)
-

* Architecture?
- TODO namespace packages
- TODO mention elisp ?

** TODO config?
** extending
** TODO cachew?
currently sqlite, but maybe in postgres/redis?
thanks to SqlAlchemy might be almost trivial

* Data flow?

* Why Python?
# maybe move to the end?
- mypy
- dataclasses
- decorators
- iterators
- packages
  # namespace packages
- malleable
  # not as malleable

** HPI -> HTTP
TODO observable notebook?

** HPI -> Sqlite
TODO datasette demo?

** HPI -> JSON
TODO demo query/jq thing?

* Error handling

Very important!
mypy :heart:
TODO example of 'opt-in' error handling?

* Storage
- how much space it takes?
- syncing
- bleanser?


* Integrations
** TODO grafana?

* What's next?
# 7-10 minutes?
Rough ideas: https://beepb00p.xyz/exobrain/projects/hpi.html
** more user interfaces
# haven't done as many integrations as I wish I did
# TODO links?
- grafana
  # already started, but would be nice to make it a bit more automatic
- datasette
  https://datasette.io
  # existing rich ecosystem of tools for data exploration & publishing
  # 'downside' -- against sqlite databases
  # but possible to interface, cachew!
- solid
  https://solidproject.org/about
  # decentralized pods, apps
- memri
  # 'data browser'
  https://github.com/memri/pod
- openhumans.org
  https://www.openhumans.org/about
  # quantified self / data analysis notebooks
- perkeep
  https://perkeep.org
  # a set of open source formats, protocols
  #  and software for modeling, storing, searching, sharing and synchronizing data

** inter-language interfaces
For people who don't like Python ;)
# translate data to other languages
# but also for performance, interoperation, etc
# julia?
- apache arrow?
  https://arrow.apache.org
- json api =hpi query=
- HTTP api https://github.com/seanbreckenridge/HPI_API
** community
For everyone interested in data liberation & bulding memexes!
https://memex.zulipchat.com

** misc
- make setup & demonstrations easier
  # docker isn't that simple because images are basically immutable, and it's hard to tinker with them
  # TODO python packaging etc?
  # virtual environments etc
- more modules/data?
- realtime data sources

* Questions?
- https://github.com/karlicoss/HPI#readme
- beepb00p.xyz
- twitter.com/karlicoss
- @karlicoss:matrix.org

* What's hard/unsolved?
- data is crap
  # It takes a while to reverse engineer it. E.g. even timezones etc
- data on phones is locked in
  Even more annoying that they often keep data in sqlite databases on the device already.
- how to scale/extend?
  # I can't properly maintain
  Sort of an Emacs problem
- versioning?
  kind of the same problem
  # completely unclear -- changes all the time
  # at least with code it's possible to keep it backwards compatible & test
- where to get test data?
  # would be nice if services provided test data/test API endpoints
  # or obfuscator/anonymizer for test data

* TODO misc
* TODO reveal stuff
** [2021-04-19 Mon 22:39] time estimates?
